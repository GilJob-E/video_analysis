# video_analysis


ì›¹ìº  ì˜ìƒì—ì„œ **ì‹œì„ (ì•„ì´ì»¨íƒ), ë¯¸ì†Œ, ë„ë•ì„, ì•ìœ¼ë¡œ ìˆ™ì´ê¸°** ë“±ì˜ ë¹„ì–¸ì–´ì  íŠ¹ì„±ì„ ì¶”ì¶œí•˜ê³   
ë©´ì ‘ ìƒí™©ì—ì„œì˜ **ì‹œì„  ë¹„ìœ¨ / í‘œì • / ê³ ê°œ ë„ë•ì„**ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.



## ê¸°ë°˜ ì•„ì´ë””ì–´

- Ye et al., **Low-cost Geometry-based Eye Gaze Detection using Facial Landmarks Generated through Deep Learning**  
  - ì–¼êµ´ ëœë“œë§ˆí¬ë¡œë¶€í„° 8ì°¨ì› ì‹œì„  ê¸°í•˜ íŠ¹ì„±(ëˆˆë™ì ìœ„ì¹˜, ì–¼êµ´ í¬ê¸°, ì–¼êµ´ ìœ„ì¹˜, head rotation ë“±)ì„ êµ¬ì„±í•˜ê³   
    ì´ë¥¼ ì´ìš©í•´ ì‹œì„  ë°©í–¥ì„ ì¶”ì •í•˜ëŠ” **Geometry-based Gaze** ì•„ì´ë””ì–´ë¥¼ ì°¨ìš©í–ˆìŠµë‹ˆë‹¤.
- Acarturk et al., 2021, *Gaze Aversion in Conversational Settings: An Investigation Based on Mock Job Interview*  
  - ëª¨ì˜ ë©´ì ‘ í™˜ê²½ì—ì„œ ì‹œì„  íšŒí”¼/ì•„ì´ì»¨íƒ ë¹„ìœ¨ì„ ì •ëŸ‰ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬,  
    ë©´ì ‘ ìƒí™©ì—ì„œì˜ **â€œí‰ê· ì ì¸ eye contact ë¹„ìœ¨â€**ê³¼ ê·¸ **ë¶„ì‚°(í‘œì¤€í¸ì°¨)**ì— ëŒ€í•œ ê·œë²”ê°’ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.
- Esmer, 2022, *An Experimental Investigation of Gaze Behavior Modeling in VR (MSc Thesis)*  
  - VR í™˜ê²½ì—ì„œì˜ ì‹œì„  í–‰ë™ ëª¨ë¸ë§ ì‹¤í—˜ì„ ê¸°ë°˜ìœ¼ë¡œ, **ì‹œì„  ìœ ì§€/íšŒí”¼ ë¹„ìœ¨ ë¶„í¬**ë¥¼ ë³´ì •í•˜ëŠ” ë° ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.

ë³¸ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìœ„ ì•„ì´ë””ì–´ ë° í†µê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ,  
**â€œí™”ë©´ ì¤‘ì•™ í•œ ì  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ â†’ í”„ë ˆì„ ë‹¨ìœ„ ì‹œì„  ê¸°í•˜ íŠ¹ì„± ê³„ì‚° â†’ ì•„ì´ì»¨íƒ ì—¬ë¶€ ë° ë¹„ìœ¨ ì‚°ì¶œâ€** íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.



## ì„¤ì¹˜

### 1) ì˜ì¡´ì„±

```bash
pip install opencv-python mediapipe numpy
```

- Python >= 3.9 ê¶Œì¥
- ì›¹ìº (ë˜ëŠ” ê°€ìƒ ì¹´ë©”ë¼) í•„ìš”

### 2) íŒŒì¼ ë°°ì¹˜

```text
project/
â”œâ”€â”€ face.py               # ì´ READMEê°€ ì„¤ëª…í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ face_landmarker.task   # MediaPipe FaceLandmarker ëª¨ë¸ íŒŒì¼
```

`face.py`ì™€ `face_landmarker.task`ë¥¼ **ê°™ì€ í´ë”**ì— ë‘ì–´ì•¼ í•©ë‹ˆë‹¤.



## ë¹ ë¥¸ ì‹œì‘

```bash
python face.py
```

ì‹¤í–‰í•˜ë©´ ë‘ ë‹¨ê³„ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.

1. **ì¤‘ì•™ í•œ ì  ìº˜ë¦¬ë¸Œë ˆì´ì…˜**
   - `Center Calibration` ì°½ì´ ì—´ë¦½ë‹ˆë‹¤.
   - í™”ë©´ ì¤‘ì•™ì˜ ì´ˆë¡ìƒ‰ ì ì„ ë°”ë¼ë³´ê³ ,
   - ì¤€ë¹„ë˜ë©´ **í‚¤ë³´ë“œ `c`** ë¥¼ ëˆŒëŸ¬ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.
   - ì•½ `num_samples` í”„ë ˆì„(ê¸°ë³¸ 120í”„ë ˆì„) ë™ì•ˆ ìë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ëª¨ìë‹ˆë‹¤.
   - ì–¸ì œë“  **`q`** í‚¤ë¡œ ì¢…ë£Œ ê°€ëŠ¥.

2. **ì¸í„°ë·° ì„¸ì…˜(Interview Session)**
   - `Interview (Eye Contact)` ì°½ì´ ì—´ë¦½ë‹ˆë‹¤.
   - ì›¹ìº ì„ ë°”ë¼ë³´ë©° í‰ì†Œì²˜ëŸ¼ ë§í•˜ë©´,
     - ì•„ì´ì»¨íƒ ì—¬ë¶€,
     - ì•„ì´ì»¨íƒ ë¹„ìœ¨,
     - z-score,
     - í‰ê·  ë¯¸ì†Œ ê°•ë„,
     - ë„ë•ì„ íšŸìˆ˜
     ë“±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— ì˜¤ë²„ë ˆì´í•©ë‹ˆë‹¤.
   - **`q`** í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì„¸ì…˜ì´ ì¢…ë£Œë˜ê³ ,  
     í„°ë¯¸ë„ì— ì „ì²´ ìš”ì•½ì´ ì¶œë ¥ë©ë‹ˆë‹¤.



## Ye et al. ê¸°ë°˜ Eye-contact ë¡œì§ íë¦„

Ye et al.ì˜ ë…¼ë¬¸ì€ **ì–¼êµ´ ëœë“œë§ˆí¬ë§Œìœ¼ë¡œ ì €ë¹„ìš© ì‹œì„  ì¶”ì •ì„ ìˆ˜í–‰**í•˜ê¸° ìœ„í•´, ë‹¤ìŒê³¼ ê°™ì€ íë¦„ì„ ì œì•ˆí•©ë‹ˆë‹¤.

1. **ì–¼êµ´ ëœë“œë§ˆí¬ â†’ Geometry Feature ì¶”ì¶œ**
   - ëˆˆ ì£¼ë³€/ì–¼êµ´ì˜ íŠ¹ì • ëœë“œë§ˆí¬ ì¢Œí‘œë¥¼ ì‚¬ìš©í•´,
     - ëˆˆë™ì ìœ„ì¹˜ í¸ì°¨(PPx, PPy)
     - ì–¼êµ´ íšŒì „(RX: pitch, RY: yaw)
     - ì–¼êµ´ í¬ê¸°(Hf, Wf)
     - ì–¼êµ´ì˜ ì´ë¯¸ì§€ ë‚´ ìœ„ì¹˜(PME_x, PME_y)
   - ì´ 8ì°¨ì› ë²¡í„°ë¡œ êµ¬ì„±ëœ **Geometry-based Gaze Feature**ë¥¼ ë§Œë“­ë‹ˆë‹¤.

2. **ì •ë©´(eye contact) ìƒíƒœì— ëŒ€í•œ ê¸°ì¤€ ë¶„í¬ í•™ìŠµ**
   - ì‚¬ëŒì´ **ì •ë©´(ë˜ëŠ” íŠ¹ì • íƒ€ê¹ƒ)ì„ ì‘ì‹œí•˜ëŠ” ìƒíƒœ**ì—ì„œ ìœ„ 8D featureë¥¼ ì—¬ëŸ¬ ìƒ˜í”Œë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
   - ì´ ë¶„í¬ë¥¼ ì´ìš©í•´
     - í‰ê·  ë²¡í„° Î¼ (8ì°¨ì›)
     - í‘œì¤€í¸ì°¨ ë²¡í„° Ïƒ (8ì°¨ì›)
   ì„ êµ¬í•˜ê³ , â€œì •ë©´ ì‘ì‹œâ€ ìƒíƒœì˜ **ê¸°ì¤€ ì˜ì—­**ì„ ì •ì˜í•©ë‹ˆë‹¤.

3. **ìƒˆ í”„ë ˆì„ì— ëŒ€í•œ z-score ë° í¸ì°¨ ê³„ì‚°**
   - ìƒˆë¡œìš´ í”„ë ˆì„ì—ì„œ ì–»ì€ feature `f`ì— ëŒ€í•´
     - `z = (f - Î¼) / Ïƒ` (ê° ì°¨ì›ë³„ z-score)
   - ê·¸ ì¤‘ì—ì„œ **ëˆˆ/ë¨¸ë¦¬ ê´€ë ¨ ì°¨ì›**ë“¤(PPx, PPy, RX, RY)ì˜ ê¸¸ì´ë¥¼ ì‚¬ìš©í•´
     - `dev_eye  = sqrt(z_PPx^2 + z_PPy^2)`
     - `dev_head = sqrt(z_RX^2  + z_RY^2)`
   - ì¦‰, â€œì •ë©´ ê¸°ì¤€ ë¶„í¬ì—ì„œ ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€â€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.

4. **Thresholdë¥¼ ì´ìš©í•œ Eye-contact íŒì •**
   - Ye et al.ì˜ ì•„ì´ë””ì–´ë¥¼ ë”°ë¼,
     - dev_eye, dev_headê°€ ì„¤ì •í•œ ì„ê³„ê°’(thr_eye, thr_head) ì•ˆì— ìˆìœ¼ë©´  
       â†’ **ì •ë©´ ì‘ì‹œ(eye contact)** ë¡œ íŒë‹¨
     - ì„ê³„ê°’ì„ ë„˜ì–´ê°€ë©´  
       â†’ ì‹œì„  íšŒí”¼(ë˜ëŠ” ë‹¤ë¥¸ ê³³ ì‘ì‹œ)ë¡œ ê°„ì£¼
   - ë³¸ êµ¬í˜„ì—ì„œëŠ” ì´ ë…¼ë¦¬ë¥¼ **Rule-based ë°©ì‹**ìœ¼ë¡œ ë‹¨ìˆœí™”í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.

ìš°ë¦¬ êµ¬í˜„ì˜ `eye_contact_from_features_ye` í•¨ìˆ˜ëŠ” ìœ„ íë¦„ì„ ê·¸ëŒ€ë¡œ ë”°ë¼ê°€ë˜,  
Ye et al.ì˜ ë¶„ë¥˜ê¸°ë¥¼ ëŒ€ì‹ í•´ **í¸ì°¨ ê¸°ë°˜ ì ìˆ˜(final_score)** ë¥¼ ê³„ì‚°í•˜ì—¬ ì—°ì†ì ì¸ 0~1 ìŠ¤ì½”ì–´ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.



## ì¶”ì¶œ íŠ¹ì„±

### Target Features (ì„¸ì…˜ ìš”ì•½ì— ì¶œë ¥ë˜ëŠ” í•µì‹¬ ì§€í‘œ)

| íŠ¹ì„±               | ì„¤ëª…                                                 | ì¹´í…Œê³ ë¦¬    |
|--------------------|------------------------------------------------------|------------|
| `eye_contact_ratio`| ì–¼êµ´ì´ ê²€ì¶œëœ í”„ë ˆì„ ì¤‘ ì•„ì´ì»¨íƒìœ¼ë¡œ íŒì •ëœ ë¹„ìœ¨(0~1) | Gaze       |
| `z_eye`            | ì™¸ë¶€ í†µê³„(Î¼=0.70, Ïƒ=0.15) ê¸°ì¤€ eye_contact_ratio Z-Score | Gaze   |
| `avg_smile_0_100`  | ì„¸ì…˜ ë™ì•ˆ í‰ê·  ë¯¸ì†Œ ê°•ë„ (0~100, Duchenne smile ê¸°ë°˜) | Expression |
| `nod_count`        | ë©´ì ‘ ì¤‘ ê³ ê°œë¥¼ ë„ë•ì¸ íšŸìˆ˜                           | Head Movement |

> ğŸ§® eye-contact ê¸°ì¤€ í†µê³„  
> `EYE_CONTACT_MEAN_RATIO = 0.70`  
> `EYE_CONTACT_STD_RATIO  = 0.15`  
> ìœ„ ê°’ì€ **ëª¨ì˜ ë©´ì ‘ ë° VR ê¸°ë°˜ ì‹œì„  ì—°êµ¬(Acarturk et al., 2021; Esmer, 2022)**ì—ì„œ ë³´ê³ ëœ  
> í‰ê· ì ì¸ ì‹œì„  ìœ ì§€/íšŒí”¼ ë¹„ìœ¨ ë¶„í¬ë¥¼ ì°¸ê³ í•˜ì—¬ ì„¤ì •í•œ ê·œë²”ê°’ì…ë‹ˆë‹¤.



### ì „ì²´ ì¶”ì¶œ íŠ¹ì„±

#### 1) 8D Geometry Gaze Feature (Ye ìŠ¤íƒ€ì¼, í”„ë ˆì„ ë‹¨ìœ„)

`compute_gaze_features_ye(landmarks)` â†’ ê¸¸ì´ 8ì§œë¦¬ ë²¡í„°:

| ì¸ë±ìŠ¤ | ì´ë¦„     | ì„¤ëª…                                         |
|--------|----------|----------------------------------------------|
| 0      | `PPx`    | ì–‘ ëˆˆ pupil ìœ„ì¹˜ì˜ ìˆ˜í‰ í¸ì°¨ (ì–¼êµ´ ë„ˆë¹„ ì •ê·œí™”) |
| 1      | `PPy`    | ì–‘ ëˆˆ pupil ìœ„ì¹˜ì˜ ìˆ˜ì§ í¸ì°¨ (ì–¼êµ´ ë†’ì´ ì •ê·œí™”) |
| 2      | `RX`     | ì–¼êµ´ ìƒí•˜ íšŒì „ ê´€ë ¨ head pitch proxy        |
| 3      | `RY`     | ì–¼êµ´ ì¢Œìš° íšŒì „ ê´€ë ¨ head yaw proxy          |
| 4      | `Hf`     | ì–¼êµ´ ë†’ì´(3D ê±°ë¦¬, ëˆˆ-ì½” ì‚¬ì´)              |
| 5      | `Wf`     | ì–¼êµ´ ë„ˆë¹„(3D ê±°ë¦¬, ì¢Œ/ìš° ëˆˆ ì•ˆìª½ ê¼¬ë¦¬ ì‚¬ì´) |
| 6      | `PME_x`  | ì´ë¯¸ì§€ ë‚´ ì–¼êµ´ ì¤‘ì•™ x ì¢Œí‘œ                  |
| 7      | `PME_y`  | ì´ë¯¸ì§€ ë‚´ ì–¼êµ´ ì¤‘ì•™ y ì¢Œí‘œ                  |

ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë‹¨ê³„ì—ì„œ ì´ ë²¡í„°ë“¤ì˜ **í‰ê· /í‘œì¤€í¸ì°¨**ë¥¼ ì €ì¥í•˜ê³ ,  
ì¸í„°ë·° ì„¸ì…˜ì—ì„œëŠ” `(feat - mean) / std` ë¥¼ ì´ìš©í•´ ì¤‘ì•™ì—ì„œì˜ í¸ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.



#### 2) ì•„ì´ì»¨íƒ ì§€í‘œ (í”„ë ˆì„ ë‹¨ìœ„ êµ¬í˜„)

`eye_contact_from_features_ye` ë‚´ë¶€ ë¡œì§ ê°œìš”:

- ì…ë ¥:
  - `feat` : í˜„ì¬ í”„ë ˆì„ì˜ 8D feature  
  - `mean_feat`, `std_feat` : ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì—ì„œ ì–»ì€ í‰ê· /í‘œì¤€í¸ì°¨  

```text
z = (feat - mean_feat) / std_feat

z_PPx = z[0]
z_PPy = z[1]
z_RX  = z[2]
z_RY  = z[3]

dev_eye  = sqrt(z_PPx^2 + z_PPy^2)
dev_head = sqrt(z_RX^2  + z_RY^2)

is_contact = (dev_eye <= thr_eye) and (dev_head <= thr_head)
score_eye  = max(0, 1 - dev_eye / thr_eye)
score_head = max(0, 1 - dev_head / thr_head)

final_score = 0.7 * score_eye + 0.3 * score_head
```

| íŠ¹ì„±        | ì„¤ëª…                                      |
|-------------|-------------------------------------------|
| `is_contact`| í•´ë‹¹ í”„ë ˆì„ì´ ì•„ì´ì»¨íƒ(true)ì¸ì§€ ì—¬ë¶€     |
| `score`     | 0~1 ì‚¬ì´ì˜ ì—°ì†ì ì¸ ì•„ì´ì»¨íƒ ì ìˆ˜         |
| `dev_eye`   | ëˆˆë™ì í¸ì°¨ (ì¤‘ì•™ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ì§€)  |
| `dev_head`  | ë¨¸ë¦¬ íšŒì „ í¸ì°¨                            |



#### 3) í‘œì • / ë¯¸ì†Œ

`smile(blendshapes)`:

- MediaPipe ë¸”ë Œë“œì…°ì´í”„ ì‚¬ìš©:
  - `mouthSmileLeft`, `mouthSmileRight`
  - `eyeSquintLeft`, `eyeSquintRight`
- ê¸°ë³¸ ë¯¸ì†Œ + ëˆˆì°¡ê·¸ë¦¼(Duchenne smile)ì„ ê²°í•©í•´ 0~1 ì ìˆ˜ ìƒì„±

ì„¸ì…˜ ìš”ì•½:

- `avg_smile_0_1` : ì „ì²´ face frameì— ëŒ€í•œ í‰ê·  ë¯¸ì†Œ ì ìˆ˜
- `avg_smile_0_100 = avg_smile_0_1 * 100.0`



#### 4) ë¨¸ë¦¬ ì›€ì§ì„ (ë„ë•ì„ / ì•ìœ¼ë¡œ ìˆ™ì´ê¸°)

- **ë„ë•ì„(nod)**: `detect_nod(pitch_list)`
  - ì–¼êµ´ pitch ì´ë ¥ì„ ë³´ê³ ,
  - ì¼ì • ì„ê³„ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ â€œìœ„ë¥¼ ë³´ë‹¤ê°€ ì•„ë˜ë¡œ ìˆ™ì´ê³  ë‹¤ì‹œ ì˜¬ë¦¬ëŠ”â€ íŒ¨í„´ì„ ê°ì§€

ì‚¬ìš©ë˜ëŠ” ìƒìˆ˜ ì˜ˆì‹œ:

```python
DOWN_TH = -0.10
UP_TH   = -0.05
MAX_NOD_FRAMES = 240  # ì•½ 1ì´ˆ(30fps ê¸°ì¤€)
```

- **ì•ìœ¼ë¡œ ìˆ™ì´ê¸°(lean forward)**:  
  - `detect_lean_forward(prev_nose_z, cur_nose_z, move_th=0.02)`
  - ì½”ì˜ z ê°’ì´ ì¹´ë©”ë¼ ìª½ìœ¼ë¡œ ì¼ì • ê±°ë¦¬ ì´ìƒ ê°€ê¹Œì›Œì¡Œì„ ë•Œ True  
  - (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì—ì„œëŠ” í†µê³„ ì¶œë ¥ë³´ë‹¤ ì´ë²¤íŠ¸ ê°ì§€ì— ì¤‘ì )


## API ì‚¬ìš©ë²• (ëª¨ë“ˆ import í™œìš©)

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¨ìˆœ ì‹¤í–‰í•˜ëŠ” ê²ƒ ì™¸ì—, ëª¨ë“ˆë¡œ importí•´ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## 1. Dependencies

### 1.1 Python Version

- Python **3.9 ì´ìƒ** ê¶Œì¥

### 1.2 Required Packages

`face.py`ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì™¸ë¶€ íŒ¨í‚¤ì§€:

```python
import cv2
import numpy as np
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
```

ë”°ë¼ì„œ ë‹¤ìŒ íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.

```bash
pip install opencv-python mediapipe numpy
```

### 1.3 Model File

- MediaPipe Face Landmarker ëª¨ë¸ íŒŒì¼:

```text
face_landmarker.task
```

- íŒŒì¼ ìœ„ì¹˜:
  - `face.py`ì™€ **ê°™ì€ í´ë”**ì— ë‘ì–´ì•¼ í•©ë‹ˆë‹¤.

```python
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(BASE_DIR, "face_landmarker.task")

if not os.path.exists(model_path):
    raise FileNotFoundError("'face_landmarker.task' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ë‘ì„¸ìš”.")
```

---

## 2. Basic API Usage

`face.py`ëŠ” í¬ê²Œ ì„¸ ë‹¨ê³„ë¥¼ ìœ„í•œ APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.

1. Face Landmarker ì´ˆê¸°í™”
2. ì¤‘ì•™ í•œ ì  ìº˜ë¦¬ë¸Œë ˆì´ì…˜
3. ì¸í„°ë·° ì„¸ì…˜(ì•„ì´ì»¨íƒ/ë¯¸ì†Œ/ë„ë•ì„ ì¶”ì )

### 2.1 ëª¨ë“ˆ ì„í¬íŠ¸

```python
from face import (
    build_face_landmarker,
    run_center_calibration,
    run_interview_session,
    detect_landmarks,
    compute_gaze_features_ye,
    eye_contact_from_features_ye,
    smile,
    detect_nod,
    detect_lean_forward,
    head_pose_matrix,
    matrix_to_euler,
    get_blendshape_map
)
```

> ì‹¤ì œ íŒŒì¼ ì´ë¦„ì´ `face.py`ê°€ ì•„ë‹ˆë¼ë©´, í•´ë‹¹ íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½í•´ì„œ import í•´ì•¼ í•©ë‹ˆë‹¤.

---

### 2.2 Face Landmarker ì´ˆê¸°í™”

```python
detector = build_face_landmarker()
```

- MediaPipe `FaceLandmarker`ë¥¼ **VIDEO ëª¨ë“œ**ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
- ì˜µì…˜:
  - `num_faces=1`
  - `min_face_detection_confidence=0.5`
  - `min_face_presence_confidence=0.5`
  - `min_tracking_confidence=0.5`
  - `output_face_blendshapes=True`
  - `output_facial_transformation_matrixes=True`

---

### 2.3 ì¤‘ì•™ í•œ ì  ìº˜ë¦¬ë¸Œë ˆì´ì…˜

ì‚¬ìš©ìê°€ í™”ë©´ ì¤‘ì•™ì˜ ì ì„ ë°”ë¼ë³´ë„ë¡ í•˜ê³ ,  
Ye ìŠ¤íƒ€ì¼ 8D geometry featureì˜ í‰ê· /í‘œì¤€í¸ì°¨ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.

```python
mean_feat, std_feat = run_center_calibration(detector, num_samples=120)
```

- `num_samples`:
  - ìˆ˜ì§‘í•  í”„ë ˆì„ ìˆ˜ (ê¸°ë³¸ 120 â‰ˆ 4ì´ˆ @30fps)
- ë°˜í™˜ê°’:
  - `mean_feat`: 8D feature í‰ê·  (numpy array, shape `(8,)`)
  - `std_feat` : 8D feature í‘œì¤€í¸ì°¨ (numpy array, shape `(8,)`)

---

### 2.4 ì¸í„°ë·° ì„¸ì…˜ ì‹¤í–‰

ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼(`mean_feat`, `std_feat`)ë¥¼ ì‚¬ìš©í•´  
ì‹¤ì‹œê°„ìœ¼ë¡œ ì•„ì´ì»¨íƒ/ë¯¸ì†Œ/ë„ë•ì„ì„ ì¶”ì í•©ë‹ˆë‹¤.

```python
run_interview_session(
    detector,
    mean_feat,
    std_feat,
    thr_h=2.0,  # ëˆˆ ê´€ë ¨ z-score threshold
    thr_v=4.0,  # ë¨¸ë¦¬ íšŒì „ z-score threshold
)
```

- ì›¹ìº ì„ ì—´ì–´ í”„ë ˆì„ ë‹¨ìœ„ë¡œ:
  - ì–¼êµ´ ëœë“œë§ˆí¬, ë¸”ë Œë“œì…°ì´í”„, head pose ì¶”ì¶œ
  - Ye 8D feature ê³„ì‚° â†’ ì¤‘ì•™ ê¸°ì¤€ z-score â†’ eye-contact íŒì •
  - Duchenne smile ìŠ¤ì½”ì–´ ê³„ì‚°
  - pitch ì´ë ¥ìœ¼ë¡œ nod ê°ì§€
- í™”ë©´ ì˜¤ë²„ë ˆì´ ì •ë³´:
  - Eye-contact ratio
  - Eye-contact score
  - z-eye score
  - í‰ê·  Smile intensity
  - Nod Count
  - Pitch ê°’
- ì¢…ë£Œ:
  - `q` í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì„¸ì…˜ ì¢…ë£Œ í›„ ìš”ì•½ í†µê³„ ì¶œë ¥

---

### 2.5 í”„ë ˆì„ ë‹¨ìœ„ API ì‚¬ìš© ì˜ˆì‹œ

#### 2.5.1 ì–¼êµ´ íƒì§€ + ëœë“œë§ˆí¬/í‘œì •/ìì„¸

```python
import cv2
from face import build_face_landmarker, detect_landmarks

detector = build_face_landmarker()
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    landmarks, blendshapes, pitch, yaw = detect_landmarks(detector, frame)

    if landmarks is not None:
        # landmarks: MediaPipe face_landmarks
        # blendshapes: í‘œì • ë¸”ë Œë“œì…°ì´í”„
        # pitch, yaw: ë¼ë””ì•ˆ ë‹¨ìœ„ ë¨¸ë¦¬ íšŒì „
        pass

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

---

#### 2.5.2 8D Gaze Feature + Eye-contact ìˆ˜ë™ ê³„ì‚°

```python
import numpy as np
from face import (
    compute_gaze_features_ye,
    eye_contact_from_features_ye,
)

# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì—ì„œ ì–»ì€ mean_feat, std_feat
mean_feat = ...
std_feat = ...

feat = compute_gaze_features_ye(landmarks)  # landmarksëŠ” MediaPipe ê²°ê³¼

is_contact, score, dev_eye, dev_head = eye_contact_from_features_ye(
    feat,
    mean_feat,
    std_feat,
    thr_eye=2.0,
    thr_head=4.0,
)

print("Eye-contact:", is_contact, "score=", score)
```

---

#### 2.5.3 Smile / Nod / Lean Forward ë‹¨ë… ì‚¬ìš©

```python
from face import smile, detect_nod, detect_lean_forward

# 1) Smile
smile_score = smile(blendshapes)  # 0 ~ 1
print("Smile intensity:", smile_score)

# 2) Nod
pitch_history = []
pitch_history.append(pitch)  # ë§¤ í”„ë ˆì„ pitch ì¶”ê°€

if detect_nod(pitch_history):
    print("Detected nod!")

# 3) Lean forward
prev_nose_z = None
cur_nose_z = nose_landmark.z  # í”„ë ˆì„ë§ˆë‹¤ ì—…ë°ì´íŠ¸

if detect_lean_forward(prev_nose_z, cur_nose_z, move_th=0.02):
    print("Leaning forward detected!")
prev_nose_z = cur_nose_z
```

---

## 3. CLI Usage

`face.py`ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒ ìˆœì„œë¡œ ë™ì‘í•©ë‹ˆë‹¤.

```bash
python face.py
```

1. `build_face_landmarker()` í˜¸ì¶œ
2. `run_center_calibration(detector, num_samples=120)` ì‹¤í–‰
3. `run_interview_session(detector, mean_feat, std_feat, thr_h=2.0, thr_v=1.5)` ì‹¤í–‰

ì›¹ìº  ì°½ 2ê°œê°€ ìˆœì„œëŒ€ë¡œ ëœ¨ë©°,  
- ì²« ë²ˆì§¸ ì°½: **Center Calibration**
- ë‘ ë²ˆì§¸ ì°½: **Interview (Eye Contact)**  
q í‚¤ë¡œ ê° ë‹¨ê³„ ì¢…ë£Œê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.




## ì •ê·œí™” (Normalization)

### 1) Gaze Feature Z-Score (ì¤‘ì•™ ê¸°ì¤€)

- ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë‹¨ê³„:

```python
feats = np.stack(feats, axis=0)  # (N, 8)

mean_feat = feats.mean(axis=0)
std_feat  = feats.std(axis=0, ddof=0)
std_feat  = np.where(std_feat < 1e-6, 1e-6, std_feat)  # 0 ë¶„ì‚° ë°©ì§€
```

- ì¸í„°ë·° ì„¸ì…˜ì—ì„œ ê° í”„ë ˆì„:

```python
z = (feat - mean_feat) / std_feat
```

ì´ ê°’ì„ ë°”íƒ•ìœ¼ë¡œ **dev_eye / dev_head**ë¥¼ ê³„ì‚°í•´  
â€œì¤‘ì•™ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ì§€â€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.

### 2) Eye-contact Ratio Z-Score (ì™¸ë¶€ í†µê³„ ê¸°ë°˜)

ì¸í„°ë·°ê°€ ëë‚œ í›„ ì „ì²´ ìš”ì•½ì—ì„œ:

```python
eye_ratio = eye_contact_frames / total_face_frames
z_eye = (eye_ratio - EYE_CONTACT_MEAN_RATIO) / EYE_CONTACT_STD_RATIO
# EYE_CONTACT_MEAN_RATIO = 0.70
# EYE_CONTACT_STD_RATIO  = 0.15
```

- `z_eye > 0` : í‰ê· ë³´ë‹¤ ë” ë§ì´ ì¹´ë©”ë¼ë¥¼ ë´„  
- `z_eye â‰ˆ 0` : í‰ê· ì ì¸ ìˆ˜ì¤€  
- `z_eye < 0` : í‰ê· ë³´ë‹¤ ì ê²Œ ì¹´ë©”ë¼ë¥¼ ë´„  



## í”„ë¡œì íŠ¸ êµ¬ì¡°

í˜„ì¬ëŠ” ë‹¨ì¼ ìŠ¤í¬ë¦½íŠ¸ êµ¬ì¡°ì…ë‹ˆë‹¤.

```text
.
â”œâ”€â”€ face.py               # ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ + ì¸í„°ë·° ì„¸ì…˜)
â””â”€â”€ face_landmarker.task   # MediaPipe FaceLandmarker ëª¨ë¸
```



## í•œê³„ì 

1. **í™˜ê²½ ë¯¼ê°ë„**
   - ì¹´ë©”ë¼ ìœ„ì¹˜, í•´ìƒë„, ì¡°ëª…, í™”ë©´ í¬ê¸°ì— ë”°ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜/ì„ê³„ê°’ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **íŒŒë¼ë¯¸í„° í•´ì„**
   - `DOWN_TH = -0.10` `UP_TH   = -0.05`ëŠ” ì§ì ‘ í…ŒìŠ¤íŠ¸í•œ ê²°ê³¼ì´ê³ ,
   - smileì˜ z-scoreë¥¼ ê³„ì‚°í•  ë•Œ ì‚¬ìš© í•œ ê°’ì€ kaggleì˜ First Impressions V2 (CVPR'17) - Training ë°ì´í„°ì…‹ì„ ì¼ë¶€ ì‚¬ìš©
3. **ì˜ë¯¸ê°€ ìˆëŠ”ê°€**
   - ëŒ€ë‹µë§Œì„ í•˜ëŠ” ì˜ìƒì„ ì…ë ¥ìœ¼ë¡œ ë°›ìœ¼ë©´ smile, nodê°€ ëŒ€ë‹µê³¼ ë™ì‹œì— ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆëŠ”ì§€?



## ì°¸ê³  ë¬¸í—Œ

- Acarturk, C. et al. (2021). *Gaze Aversion in Conversational Settings: An Investigation Based on Mock Job Interview.*  
- Esmer, B. (2022). *An Experimental Investigation of Gaze Behavior Modeling in VR.* MSc Thesis.  
- Ye, X. et al. *Low-cost Geometry-based Eye Gaze Detection using Facial Landmarks Generated through Deep Learning.*  
- MediaPipe Face Landmarker (Face mesh & blendshapes & transformation matrix).
